<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8" />
	<title>Web Audio 2</title>
	<style>
		canvas{border:1px solid black;display:block;}

        *{font-family:sans-serif;}
        span{margin-right:2em;}
        #slider-distortion{position:relative;top:.7em;}
	</style>
</head>
<body>
    <p>
        <span><label for="cb-highshelf">Highshelf Filter (Treble)</label><input type="checkbox" id="cb-highshelf"></span>
        <span><label for="cb-lowshelf">Lowshelf Filter (Bass)</label><input type="checkbox" id="cb-lowshelf"></span>
        <span><label for="cb-distortion">Distortion</label><input type="checkbox" id="cb-distortion"></span>
        <span>0 <input type="range" min="0" max="100" value="0" id="slider-distortion"> 100</span>
      </p>
    <canvas width="640" height="480"></canvas>

<!-- use obama-oilspill.mp3 or human-voice.mp3 -->
<audio controls src="sounds/obama-oilspill.mp3"></audio>

<script>
	const NUM_SAMPLES = 64;
	// 1 - get reference to <audio> element on page
	let audioElement = document.querySelector('audio');
			
	// 2 - create a new `AudioContext` object
	// https://developer.mozilla.org/en-US/docs/Web/API/AudioContext
	let audioCtx = new (window.AudioContext || window.webkitAudioContext); // to support Safari and mobile
	
	// 3 - create a node that points at the <audio> element
	// https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaElementSource
	let sourceNode = audioCtx.createMediaElementSource(audioElement); 
	
	// 4 - create a *analyser node*
	// https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode
	// this gets us real-time frequency and time-domain (i.e. waveform) information
	let analyserNode = audioCtx.createAnalyser();
	
	// 5 - How many samples do we want? fft stands for Fast Fourier Transform
	analyserNode.fftSize = NUM_SAMPLES;
	
	// 6 - hook up the <audio> element to the analyserNode
	sourceNode.connect(analyserNode);
	
	// 7 - connect to the destination i.e. the speakers
	analyserNode.connect(audioCtx.destination);
	
	// 8 - create a new array of 8-bit integers (0-255)
	  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array
	  let data = new Uint8Array(analyserNode.frequencyBinCount); // OR analyserNode.fftSize/2
	
	// Chrome autoplay fix
	// https://developers.google.com/web/updates/2017/09/autoplay-policy-changes
	document.querySelector("audio").onplay = (e) => {
  	  if (audioCtx.state == "suspended") {
    	    audioCtx.resume();
  	  }
	};
	
	// canvas stuff
	let ctx = document.querySelector("canvas").getContext("2d");
	const BAR_WIDTH = 15;
	const MAX_BAR_HEIGHT = 100;
	const PADDING = 4;
	const MIDDLE_Y = ctx.canvas.height/2;
    let highshelf = false;
    let biquadFilter = audioCtx.createBiquadFilter();
    biquadFilter.type = "highshelf";
	
	setupUI();
	
	loop();

    function setupUI(){
        // I. set the initial state of the high shelf checkbox
        document.querySelector('#cb-highshelf').checked = highshelf; // `highshelf` is a boolean we will declare in a second
        
        // II. change the value of `highshelf` every time the high shelf checkbox changes state
        document.querySelector('#cb-highshelf').onchange = e => {
            highshelf = e.target.checked;
            toggleHighshelf(); // turn on or turn off the filter, depending on the value of `highshelf`!
        };
        
        // III. 
        toggleHighshelf(); // when the app starts up, turn on or turn off the filter, depending on the value of `highshelf`!
    }

    function toggleHighshelf(){
        if(highshelf){
            biquadFilter.frequency.setValueAtTime(1000, audioCtx.currentTime); // we created the `biquadFilter` (i.e. "treble") node last time
            biquadFilter.gain.setValueAtTime(25, audioCtx.currentTime);
        }else{
            biquadFilter.gain.setValueAtTime(0, audioCtx.currentTime);
        }
    }
	
	function loop() { 
	  // 9 - this schedules a call to the loop() method in 1/60 second
	  requestAnimationFrame(loop);
		
	 
		
	  // 10 - populate the array with the frequency data
	  // notice these arrays are passed *by reference*
	  analyserNode.getByteFrequencyData(data);
		
	  // 11 - this time, let's visualize the audio data on the canvas
		
     	  /* YOU WRITE THIS! */
          ctx.fillStyle = "rgba(0,0,0,.1)";
          ctx.fillRect(0,0,ctx.canvas.width, ctx.canvas.height);
          //ctx.fillStyle = "red";
          ctx.save();
          ctx.translate(320, MIDDLE_Y - 100);
          for(let b of data){
            let percent = b/255;
            if(percent < .02) percent = 0.02;
            ctx.translate(BAR_WIDTH, 0);
            ctx.rotate(Math.PI * 2/32)
            ctx.save();
            ctx.scale(1,-1);
            ctx.fillStyle = `rgb(${b}, ${b-128},${255-b})`;
            ctx.fillRect(0,0,BAR_WIDTH,MAX_BAR_HEIGHT * percent);
            ctx.restore();
            ctx.translate(PADDING, 0);//add space between bars
          }
          ctx.restore();

          //line
          ctx.save();
          ctx.strokeStyle = "white";
          ctx.lineWidth = 3;
          let x = -(ctx.canvas.width/data.length) 
          let y = MIDDLE_Y + 200;
          ctx.beginPath();
          ctx.moveTo(x, y);
          for(let b of data){
            ctx.lineTo(x, y-b);
            x += (ctx.canvas.width/(data.length-10));
          }
          ctx.stroke();
          ctx.closePath();
          ctx.restore();
    
	}
	
</script>
</body>
</html>